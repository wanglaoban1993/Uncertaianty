{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2502894d830>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    " \n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2) \n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"] \n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE)) \n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "register_matplotlib_converters()\n",
    " \n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>_conds</th>\n",
       "      <th>_dewptm</th>\n",
       "      <th>_fog</th>\n",
       "      <th>_hail</th>\n",
       "      <th>_heatindexm</th>\n",
       "      <th>_hum</th>\n",
       "      <th>_precipm</th>\n",
       "      <th>_pressurem</th>\n",
       "      <th>_rain</th>\n",
       "      <th>_snow</th>\n",
       "      <th>_tempm</th>\n",
       "      <th>_thunder</th>\n",
       "      <th>_tornado</th>\n",
       "      <th>_vism</th>\n",
       "      <th>_wdird</th>\n",
       "      <th>_wdire</th>\n",
       "      <th>_wgustm</th>\n",
       "      <th>_windchillm</th>\n",
       "      <th>_wspdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19961101-11:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19961101-12:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19961101-13:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19961101-14:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19961101-16:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100985</th>\n",
       "      <td>20170424-06:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100986</th>\n",
       "      <td>20170424-09:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100987</th>\n",
       "      <td>20170424-12:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100988</th>\n",
       "      <td>20170424-15:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100989</th>\n",
       "      <td>20170424-18:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100990 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          datetime_utc  _conds   _dewptm   _fog   _hail   _heatindexm   _hum  \\\n",
       "0       19961101-11:00   Smoke       9.0      0       0           NaN   27.0   \n",
       "1       19961101-12:00   Smoke      10.0      0       0           NaN   32.0   \n",
       "2       19961101-13:00   Smoke      11.0      0       0           NaN   44.0   \n",
       "3       19961101-14:00   Smoke      10.0      0       0           NaN   41.0   \n",
       "4       19961101-16:00   Smoke      11.0      0       0           NaN   47.0   \n",
       "...                ...     ...       ...    ...     ...           ...    ...   \n",
       "100985  20170424-06:00    Haze      17.0      0       0           NaN   25.0   \n",
       "100986  20170424-09:00    Haze      14.0      0       0           NaN   16.0   \n",
       "100987  20170424-12:00    Haze      12.0      0       0           NaN   14.0   \n",
       "100988  20170424-15:00    Haze      15.0      0       0           NaN   27.0   \n",
       "100989  20170424-18:00    Haze      15.0      0       0           NaN   30.0   \n",
       "\n",
       "         _precipm   _pressurem   _rain   _snow   _tempm   _thunder   _tornado  \\\n",
       "0             NaN       1010.0       0       0     30.0          0          0   \n",
       "1             NaN      -9999.0       0       0     28.0          0          0   \n",
       "2             NaN      -9999.0       0       0     24.0          0          0   \n",
       "3             NaN       1010.0       0       0     24.0          0          0   \n",
       "4             NaN       1011.0       0       0     23.0          0          0   \n",
       "...           ...          ...     ...     ...      ...        ...        ...   \n",
       "100985        NaN       1005.0       0       0     34.0          0          0   \n",
       "100986        NaN       1003.0       0       0     38.0          0          0   \n",
       "100987        NaN       1002.0       0       0     36.0          0          0   \n",
       "100988        NaN       1004.0       0       0     32.0          0          0   \n",
       "100989        NaN       1005.0       0       0     30.0          0          0   \n",
       "\n",
       "         _vism   _wdird  _wdire   _wgustm   _windchillm   _wspdm  \n",
       "0          5.0    280.0    West       NaN           NaN      7.4  \n",
       "1          NaN      0.0   North       NaN           NaN      NaN  \n",
       "2          NaN      0.0   North       NaN           NaN      NaN  \n",
       "3          2.0      0.0   North       NaN           NaN      NaN  \n",
       "4          1.2      0.0   North       NaN           NaN      0.0  \n",
       "...        ...      ...     ...       ...           ...      ...  \n",
       "100985     4.0    320.0      NW       NaN           NaN     11.1  \n",
       "100986     4.0    320.0      NW       NaN           NaN     22.2  \n",
       "100987     4.0    270.0    West       NaN           NaN     18.5  \n",
       "100988     2.0    320.0      NW       NaN           NaN      3.7  \n",
       "100989     2.0    320.0      NW       NaN           NaN      3.7  \n",
       "\n",
       "[100990 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../data/testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>17.217391</td>\n",
       "      <td>68.043478</td>\n",
       "      <td>3.547826</td>\n",
       "      <td>1015.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2016-12-29</td>\n",
       "      <td>15.238095</td>\n",
       "      <td>87.857143</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1016.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>14.095238</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>1017.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>15.052632</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.325000</td>\n",
       "      <td>1016.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date   meantemp    humidity  wind_speed  meanpressure\n",
       "0     2013-01-01  10.000000   84.500000    0.000000   1015.666667\n",
       "1     2013-01-02   7.400000   92.000000    2.980000   1017.800000\n",
       "2     2013-01-03   7.166667   87.000000    4.633333   1018.666667\n",
       "3     2013-01-04   8.666667   71.333333    1.233333   1017.166667\n",
       "4     2013-01-05   6.000000   86.833333    3.700000   1016.500000\n",
       "...          ...        ...         ...         ...           ...\n",
       "1457  2016-12-28  17.217391   68.043478    3.547826   1015.565217\n",
       "1458  2016-12-29  15.238095   87.857143    6.000000   1016.904762\n",
       "1459  2016-12-30  14.095238   89.666667    6.266667   1017.904762\n",
       "1460  2016-12-31  15.052632   87.000000    7.325000   1016.100000\n",
       "1461  2017-01-01  10.000000  100.000000    0.000000   1016.000000\n",
       "\n",
       "[1462 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'../data/DailyDelhiClimateTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1462, 4) (114, 4)\n"
     ]
    }
   ],
   "source": [
    "def modfy_csv(data_model):   #Train/Test\n",
    "    df= pd.read_csv(f'../data/DailyDelhiClimate{data_model}.csv')\n",
    "    \n",
    "    df_new= df.rename(columns={'Unnamed: 0': 'true index'}).drop('date', axis= 1)\n",
    "    return df_new\n",
    "\n",
    "df_train= modfy_csv('Train')\n",
    "df_test= modfy_csv('Test')\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>17.217391</td>\n",
       "      <td>68.043478</td>\n",
       "      <td>3.547826</td>\n",
       "      <td>1015.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>15.238095</td>\n",
       "      <td>87.857143</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1016.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>14.095238</td>\n",
       "      <td>89.666667</td>\n",
       "      <td>6.266667</td>\n",
       "      <td>1017.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>15.052632</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.325000</td>\n",
       "      <td>1016.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       meantemp    humidity  wind_speed  meanpressure\n",
       "0     10.000000   84.500000    0.000000   1015.666667\n",
       "1      7.400000   92.000000    2.980000   1017.800000\n",
       "2      7.166667   87.000000    4.633333   1018.666667\n",
       "3      8.666667   71.333333    1.233333   1017.166667\n",
       "4      6.000000   86.833333    3.700000   1016.500000\n",
       "...         ...         ...         ...           ...\n",
       "1457  17.217391   68.043478    3.547826   1015.565217\n",
       "1458  15.238095   87.857143    6.000000   1016.904762\n",
       "1459  14.095238   89.666667    6.266667   1017.904762\n",
       "1460  15.052632   87.000000    7.325000   1016.100000\n",
       "1461  10.000000  100.000000    0.000000   1016.000000\n",
       "\n",
       "[1462 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### view the train--validation data in plots #############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# 可视化\n",
    "plt.figure(figsize=(10, 6))\n",
    "#sns.boxplot(data= df_new)\n",
    "print(list(df_new.columns))\n",
    "\n",
    "# Number of rows and columns for the subplots\n",
    "n_rows = 4\n",
    "n_cols = 1\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 20))\n",
    "\n",
    "# Loop through the columns and create a plot for each one\n",
    "for i, col in enumerate(df_new.columns):\n",
    "    axes[i].plot(df[col])\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## concat the train, validation and test dataframe together ###########################\n",
    "\n",
    "print('df_new:', df_new.shape, len(df_new))\n",
    "print('df_test_new:',  df_test_new.shape)\n",
    "\n",
    "# df_concat_result = pd.concat([df_new, df_test_new], axis=0)\n",
    "# print(df_concat_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modfy(inputs, sequence_length, which_columm):  ################# inputs: dataframe; sequence_length: step size; which used columm used as label #########################\n",
    "\n",
    "                                # use 14 previous days to predict the next one\n",
    "    df_numpy= inputs.values     #change DataFrame to Numpy \n",
    "    #scaler= StandardScaler()\n",
    "    scaler= MinMaxScaler()      #set values up between 0 and 1\n",
    "\n",
    "    df_numpy= scaler.fit_transform(df_numpy)\n",
    "    print(df_numpy.shape)\n",
    "\n",
    "    X, Y = [], []\n",
    "    for i in range(len(df_numpy) - sequence_length):\n",
    "        X.append(df_numpy[i:i+sequence_length])\n",
    "        Y.append(df_numpy[i+sequence_length, which_columm])  # Predicting column\"A\"\n",
    "\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    print('X, Y:', X.shape, Y.shape)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## modfy train data from 2d to 3d ######################\n",
    "X, Y= modfy(df_new, 14, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### split data for training and validation ###################################\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:(1462- 28+ 1)], Y[: (1462- 28+ 1)], test_size=0.2, random_state=42)\n",
    "print('X_train, X_valid, y_train, y_valid:', X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## modfy test data ############################\n",
    "\n",
    "X_test, y_test= modfy(df_test_new, 14, 0)\n",
    "print('X_test, y_test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Model Structure #####################\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class TimeSeriesLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_prob):\n",
    "        super(TimeSeriesLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # Predicting one value (column \"A\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.batch_norm(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        #out = self.dropout(out[:, -1, :])  # Take the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "#model = TimeSeriesLSTM(input_dim=7, hidden_dim=50, num_layers=2, dropout_prob=0.3)\n",
    "model = TimeSeriesLSTM(input_dim= 4, hidden_dim= 32, num_layers= 3, dropout_prob=0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Training ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################ random data split, minmax scaler, hidden_dim= 32, epochs 130, with Dropout 0.3, lr 0.001 #######################\n",
    "epochs = 130\n",
    "lr = 0.002\n",
    "droprate= 0.3\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs.squeeze(), y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validate the model\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val)\n",
    "        val_loss = criterion(val_outputs.squeeze(), y_val)\n",
    "    \n",
    "    # Store the losses for plotting\n",
    "    train_losses.append(loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {loss.item():.4f}, Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Plotting the training and validation loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training & Validation Loss(sklearn.random data split, minmax scaler, epochs {epochs}, lr {lr}, with Dropout {droprate})')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Var Model ###################################\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TimeSeriesLSTM_add_Var(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_prob):\n",
    "        super(TimeSeriesLSTM_add_Var, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)  # Predicting one value (column \"A\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.batch_norm(out[:, -1, :])\n",
    "        out = self.dropout(out)\n",
    "        #out = self.dropout(out[:, -1, :])  # Take the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "    def evaluate_and_compute_variance(self, x):\n",
    "        \n",
    "        device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        #self.eval()  # Set the model to evaluation mode\n",
    "        #self.train()  # Set the model to train mode\n",
    "        tensors_list = []\n",
    "\n",
    "        num_iterations= 100\n",
    "        for i in range(num_iterations):\n",
    "            #outputs = self(X_val.to(device))\n",
    "            outputs = self(x.to(device))\n",
    "            # criterion = nn.MSELoss()\n",
    "            # loss = criterion(outputs.squeeze(), y_val.to(device))\n",
    "            # print(f\"Loss at iteration {i}: {loss.item()}\")\n",
    "            tensors_list.append(outputs)\n",
    "\n",
    "        # Stack the tensors to create a 3D tensor of size (num_iterations, 131, 1)\n",
    "        stacked_tensors = torch.stack(tensors_list, dim=0)\n",
    "\n",
    "        # Compute the variance along the first dimension\n",
    "        variances = torch.var(stacked_tensors, dim=0, unbiased=False)\n",
    "\n",
    "        variances_2d = variances.reshape(287, 1)\n",
    "        return variances_2d\n",
    "    \n",
    "#model = TimeSeriesLSTM(input_dim=7, hidden_dim=50, num_layers=2, dropout_prob=0.3)\n",
    "var_model = TimeSeriesLSTM_add_Var(input_dim= 4, hidden_dim= 32, num_layers= 3, dropout_prob=0.3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(var_model.parameters(), lr=0.001)\n",
    "\n",
    "print(var_model)\n",
    "    \n",
    "# Assuming X_val and Y_val are your validation data tensors\n",
    "\n",
    "############## have a try ##############################\n",
    "variances_2d = var_model.evaluate_and_compute_variance(X_val)\n",
    "print('variances_2d:', variances_2d.size())\n",
    "print(variances_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################## Model save and load ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'LSTM_weather_state_dict_14.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")  \n",
    "#套用模型，预测输出\n",
    "loaded_model = TimeSeriesLSTM(input_dim= 4, hidden_dim= 32, num_layers= 3, dropout_prob=0.3).to(device)\n",
    "model_weight_path = os.path.abspath(os.path.join(os.getcwd(),\"/home/fe/twang/MA_copy/Uncertainty/SHAP_everything/codes/LSTM_weather_state_dict_14.pth\"))\n",
    "loaded_model.load_state_dict(torch.load(model_weight_path))\n",
    "\n",
    "print(loaded_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################################ Verify #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### Validation #############################\n",
    "print(X_val.size(), y_val.size())\n",
    "\n",
    "X_val = X_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "loaded_model = loaded_model.to(device)\n",
    "print()\n",
    "\n",
    "loaded_model.train()\n",
    "#loaded_model.eval()\n",
    "tensors_list= []\n",
    "for i in range(100):\n",
    "    \n",
    "    outputs = loaded_model(X_val)\n",
    "    print(outputs.size())\n",
    "    print(outputs.squeeze().size())\n",
    "    loss = criterion(outputs.squeeze(), y_val)\n",
    "    print(f\"Loss at iteration {i}: {loss.item()}\")\n",
    "    print()\n",
    "    tensors_list.append(outputs)\n",
    "\n",
    "# Stack the tensors to create a 3D tensor of size (100, 131, 1)\n",
    "stacked_tensors = torch.stack(tensors_list, dim=0)\n",
    "\n",
    "# Compute the variance along the first dimension\n",
    "variances = torch.var(stacked_tensors, dim=0, unbiased=False)\n",
    "\n",
    "variances_2d = variances.reshape(y_val.size(), 1)\n",
    "print('variances_2d:', variances_2d.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################### Test #######################################\n",
    "print('X_test.size(), y_test.size():', X_test.size(), y_test.size())\n",
    "\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)\n",
    "loaded_model = loaded_model.to(device)\n",
    "print()\n",
    "\n",
    "tensors_list_test= []\n",
    "loaded_model.train()\n",
    "#loaded_model.eval()\n",
    "for i in range(100):\n",
    "\n",
    "    outputs = loaded_model(X_test)\n",
    "    print(outputs.size())\n",
    "    print(outputs.squeeze().size())\n",
    "    loss = criterion(outputs.squeeze(), y_test)\n",
    "    print(f\"Loss at iteration {i}: {loss.item()}\")\n",
    "    print()\n",
    "    tensors_list_test.append(outputs)\n",
    "\n",
    "# Stack the tensors to create a 3D tensor of size (100, 131, 1)\n",
    "stacked_tensors = torch.stack(tensors_list_test, dim=0)\n",
    "\n",
    "# Compute the variance along the first dimension\n",
    "variances_test = torch.var(stacked_tensors, dim=0, unbiased=False)\n",
    "\n",
    "variances_test_2d = variances_test.reshape(y_test.size(), 1)\n",
    "print('variances_2d:', variances_test_2d.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######################## Original SHAP #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `model` is your trained LSTM model in PyTorch\n",
    "background = X_train[:800]  # or whatever subset you choose\n",
    "#background= background.to(device)\n",
    "print('background:', type(background),background.size())\n",
    "print()\n",
    "#loaded_model.train()\n",
    "#var_model.train()\n",
    "loaded_model.train()\n",
    "print(type(loaded_model))\n",
    "print()\n",
    "\n",
    "#如果问题持续存在，作为一种可能的解决方案，可以尝试不使用 CuDNN 优化的 RNN。这可以通过在模型初始化前设置 torch.backends.cudnn.enabled = False 来实现，但请注意这可能会影响模型的性能。\n",
    "torch.backends.cudnn.enabled = False\n",
    "#######################################      Kernel_Explainer  #############################################\n",
    "#explainer= shap.KernelExplainer(model, x_train_std.to_numpy().astype(np.float32)) # x is DataFrame here\n",
    "\n",
    "#######################################      Deep_Explainer    #############################################\n",
    "#explainer= shap.DeepExplainer(var_model, background.to(device))\n",
    "explainer= shap.DeepExplainer(loaded_model, background.to(device))\n",
    "\n",
    "############################# SHAP which data ############################\n",
    "#shap_values = explainer.shap_values(X_test)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "print('X_test:', X_test.shape)\n",
    "#Val_variances_2d\n",
    "print('############')\n",
    "print('shap_values:', type(shap_values), shap_values.shape)\n",
    "print('explainer.expected_value:', explainer.expected_value.shape, explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
